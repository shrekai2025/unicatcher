# UniCatcher 通用浏览器爬虫系统 - 项目开发规划方案

## 1. 项目概述

### 1.1 项目定义
UniCatcher是一个通用浏览器爬虫系统，支持两种爬取模式：
- **代码分析爬取**: 基于DOM结构和CSS选择器的传统爬取方式（第一阶段开发）
- **视觉分析爬取**: 基于Playwright + Midscene视觉AI的智能爬取方式（第二阶段开发，当前仅预留架构位置）

### 1.2 核心特性
- 通用性：可爬取任何网页内容
- 可配置：通过采集规则模板预设参数（仅展示，不可编辑）
- API驱动：外部系统调用API执行爬取任务
- 数据存储：本地SQLite数据库存储，未来如需扩展可直接重构
- 管理界面：简约轻量的Web管理后台
- 运行端口：默认3067，可在全局配置中修改

### 1.3 项目规模
- 自用项目，非企业级
- 安全性要求不高
- Windows本地开发，后续部署方案待定
- GitHub版本管理
- 基于AI vibe coding开发模式

### 1.4 开发原则
> **大局着眼，小步迭代**：每次开发需要从整体架构考虑，但单次实现的功能范围要控制适中，确保每个迭代都能产出可运行的功能模块。

## 2. 系统架构设计

### 2.1 总体架构
```
外部系统 → API接口 → 任务调度器 → 爬虫引擎 → 数据存储 → 管理界面
                                ↓
                          Selenium/Playwright → 浏览器
                                ↓
                          Midscene视觉AI → 图像识别
```

### 2.2 模块划分

#### 2.2.1 核心爬虫引擎
- **代码分析爬虫模块** (CodeSpider)
  - Selenium WebDriver + undetected_chromedriver
  - Playwright库支持
  - CSS选择器定位
  - 反检测机制

- **视觉分析爬虫模块** (VisionSpider)  
  - Midscene.js集成
  - 浏览器截图
  - AI图像识别
  - 数据提取

#### 2.2.2 数据层
- **数据库模块**
  - SQLite3 (默认)
  - PostgreSQL (可选)
  - 数据模型设计
  - 数据访问层

#### 2.2.3 API接口层
- **RESTful API**
  - 任务提交接口
  - 状态查询接口
  - 数据获取接口
  - 模板管理接口

#### 2.2.4 管理界面
- **采集规则模板管理**
  - 模板列表展示
  - 模板创建/编辑
  - 模板删除

- **数据库查看页面**
  - 简易数据展示
  - 无需登录
  - 自适应数据库结构

- **登录系统**
  - 固定账号密码 (admin/a2885828)

#### 2.2.5 配置管理
- **采集规则模板**
  - 页面入口配置
  - 采集范围/路径
  - 采集策略
  - Cookie登录信息
  - 数据保存位置

## 3. 技术选型确认

### 3.1 全栈技术栈 (T3 Stack - 全部选项)
- **框架**: T3 Stack (Next.js 14 + TypeScript + App Router)
- **API层**: tRPC (类型安全的API)
- **数据库**: SQLite + Prisma ORM (仅本地存储，未来如需扩展可直接重构)
- **认证**: NextAuth.js (固定账号 admin/a2885828)
- **样式**: Tailwind CSS (简约轻量风格)
- **状态管理**: Zustand (轻量级状态管理)
- **运行端口**: 3067 (可在`src/lib/config.ts`中配置)

### 3.2 爬虫引擎技术栈
- **代码分析爬虫**: Playwright + TypeScript (第一阶段)
  - 仅支持Chromium浏览器
  - headless模式可在全局配置中切换 (true/false)
- **视觉分析爬虫**: Playwright + Midscene.js (第二阶段开发，当前仅预留接口)
- **任务调度**: 内置异步任务队列 (基于Node.js)
- **数据处理**: TypeScript原生处理

### 3.3 开发工具
- **语言**: 100% TypeScript
- **版本控制**: Git + GitHub
- **包管理**: pnpm (更快的依赖管理)
- **代码质量**: ESLint + Prettier + TypeScript严格模式
- **开发环境**: VS Code + 推荐扩展包

### 3.4 部署技术 (待确认)
- **本地运行**: Node.js直接运行
- **容器化**: Docker (可选)
- **数据库**: 本地SQLite文件存储

## 4. 项目文件结构设计

```
unicatcher/
├── src/                              # T3应用主目录
│   ├── app/                          # Next.js 14 App Router
│   │   ├── layout.tsx                # 根布局
│   │   ├── page.tsx                  # 首页
│   │   ├── login/                    # 登录页面
│   │   │   └── page.tsx
│   │   ├── templates/                # 模板管理页面
│   │   │   └── page.tsx
│   │   ├── tasks/                    # 任务管理页面
│   │   │   └── page.tsx
│   │   ├── data/                     # 数据查看页面
│   │   │   └── page.tsx
│   │   └── api/                      # API路由 (用于外部调用)
│   │       └── spider/
│   │           └── route.ts
│   ├── components/                   # React组件
│   │   ├── ui/                       # 基础UI组件
│   │   │   ├── button.tsx
│   │   │   ├── table.tsx
│   │   │   └── form.tsx
│   │   ├── layout/                   # 布局组件
│   │   │   ├── header.tsx
│   │   │   ├── sidebar.tsx
│   │   │   └── nav.tsx
│   │   ├── templates/                # 模板相关组件
│   │   │   └── template-list.tsx
│   │   ├── tasks/                    # 任务相关组件
│   │   │   ├── task-list.tsx
│   │   │   └── task-form.tsx
│   │   └── data/                     # 数据展示组件
│   │       └── data-table.tsx
│   ├── lib/                          # 工具库和配置
│   │   ├── db.ts                     # 数据库配置
│   │   ├── auth.ts                   # NextAuth配置
│   │   ├── config.ts                 # 全局配置文件 (端口、headless等)
│   │   ├── utils.ts                  # 通用工具函数
│   │   └── validations.ts            # 数据验证schemas
│   ├── server/                       # tRPC服务端
│   │   ├── api/                      # tRPC路由
│   │   │   ├── root.ts               # 根路由
│   │   │   └── routers/
│   │   │       ├── auth.ts           # 认证路由
│   │   │       ├── templates.ts      # 模板路由
│   │   │       ├── tasks.ts          # 任务路由
│   │   │       └── data.ts           # 数据路由
│   │   ├── core/                     # 核心业务逻辑
│   │   │   ├── spider/               # 爬虫引擎
│   │   │   │   ├── base.ts           # 基础爬虫类
│   │   │   │   ├── code-spider.ts    # 代码分析爬虫 (第一阶段)
│   │   │   │   ├── vision-spider.ts  # 视觉分析爬虫 (第二阶段预留)
│   │   │   │   └── factory.ts        # 爬虫工厂
│   │   │   ├── browser/              # 浏览器管理
│   │   │   │   ├── playwright-manager.ts
│   │   │   │   └── browser-pool.ts
│   │   │   ├── midscene/             # Midscene集成 (第二阶段预留)
│   │   │   │   ├── client.ts
│   │   │   │   └── types.ts
│   │   │   └── tasks/                # 任务调度
│   │   │       ├── queue.ts          # 任务队列
│   │   │       └── scheduler.ts      # 任务调度器
│   │   └── db/                       # 数据库相关
│   │       ├── schema.ts             # Prisma schema定义
│   │       └── migrations/           # 数据库迁移文件
│   ├── store/                        # 客户端状态管理
│   │   ├── auth.ts                   # 认证状态
│   │   ├── tasks.ts                  # 任务状态
│   │   └── app.ts                    # 应用全局状态
│   ├── types/                        # TypeScript类型定义
│   │   ├── spider.ts                 # 爬虫相关类型
│   │   ├── database.ts               # 数据库类型
│   │   └── api.ts                    # API类型
│   └── styles/                       # 样式文件
│       └── globals.css               # 全局样式 (Tailwind)
├── prisma/                           # Prisma配置
│   ├── schema.prisma                 # 数据库模式
│   └── migrations/                   # 数据库迁移
├── data/                             # 数据存储目录
│   ├── database/                     # SQLite数据库文件
│   ├── logs/                         # 日志文件
│   └── browser-data/                 # 浏览器用户数据
├── scripts/                          # 工具脚本
│   ├── setup-dev.ts                  # 开发环境一键设置
│   └── seed-db.ts                    # 数据库种子数据
├── .vscode/                          # VS Code配置
│   ├── extensions.json               # 推荐扩展列表
│   ├── launch.json                   # 调试配置
│   └── settings.json                 # 工作区设置
├── .env.example                      # 环境变量示例
├── .env.local                        # 本地环境变量
├── .gitignore
├── package.json                      # 项目依赖 (pnpm)
├── tsconfig.json                     # TypeScript配置
├── tailwind.config.js                # Tailwind CSS配置
├── next.config.js                    # Next.js配置
├── prisma/schema.prisma              # Prisma数据库模式
├── README.md
└── eslint.config.js                  # ESLint配置
```

## 5. 数据库设计

### 5.1 数据库技术确认
- **数据库**: SQLite + Prisma ORM (仅本地存储)
- **数据存储**: 文件路径 `./data/database/unicatcher.db`
- **迁移管理**: Prisma Migrate
- **扩展策略**: 未来如需扩展可直接重构，无需保留存量数据

### 5.2 数据表结构
> **注意**: 具体的数据表字段和结构将在开发过程中根据实际需求逐步定义和完善。这里仅列出核心表的概念设计。

#### 5.2.1 核心数据表概念
- **采集规则模板表** (templates): 存储预设的爬取配置（仅展示，不可编辑）
- **爬取任务表** (tasks): 记录爬取任务的执行状态和结果
- **爬取数据表** (scraped_data): 存储实际爬取到的数据
- **用户会话表** (sessions): 管理用户登录状态

## 6. API接口设计

### 6.1 tRPC路由设计
基于T3架构，使用tRPC提供类型安全的API接口。

#### 6.1.1 认证路由 (auth)
```typescript
// 内部管理界面认证
auth.login         // 用户登录 (admin/a2885828)
auth.logout        // 用户登出
auth.getSession    // 获取当前会话
```

#### 6.1.2 模板管理路由 (templates)
```typescript
// 采集规则模板 (仅查看，不可编辑)
templates.getAll   // 获取所有模板列表
templates.getById  // 根据ID获取模板详情
// 注意：不提供create/update/delete，因为模板需要单独开发
```

**采集规则模板实现方式 (方案A - 硬编码)**:
- 模板文件位置: `src/server/core/spider/templates/`
- 实现方式: 每个模板为独立的TypeScript文件，导出标准化的模板对象
- 文件结构示例:
```
src/server/core/spider/templates/
├── index.ts              # 模板导出入口
├── example-news.ts       # 新闻网站模板
├── example-ecommerce.ts  # 电商网站模板
└── types.ts              # 模板类型定义
```
- 模板对象结构:
```typescript
export interface SpiderTemplate {
  id: string;
  name: string;
  description: string;
  spiderType: 'code' | 'vision';
  entryUrl: string;
  selectors?: Record<string, string>; // CSS选择器配置
  visionConfig?: Record<string, any>;  // 视觉识别配置
  cookies?: Record<string, string>;
  headers?: Record<string, string>;
  isActive: boolean;
}
```

#### 6.1.3 任务管理路由 (tasks)
```typescript
// 爬取任务管理
tasks.create       // 提交新的爬取任务
tasks.getAll       // 获取任务列表 (支持分页和筛选)
tasks.getById      // 获取任务详情
tasks.cancel       // 取消正在执行的任务
tasks.getResult    // 获取任务执行结果
```

#### 6.1.4 数据查询路由 (data)
```typescript
// 爬取数据查询
data.getAll        // 查询爬取数据 (支持分页和筛选)
data.getByTaskId   // 根据任务ID获取数据
data.export        // 导出数据 (JSON/CSV格式)
data.getStats      // 获取数据统计信息
```

### 6.2 外部API接口 (REST)
为外部系统调用提供标准REST接口：

```
POST /api/spider/task         # 外部系统提交爬取任务
GET  /api/spider/task/{id}    # 查询任务状态
GET  /api/spider/data/{id}    # 获取爬取结果
```

## 7. AI Vibe Coding 开发任务分解

> **开发模式说明**: 基于AI协助的增量式开发，每个模块从最小可用版本开始，逐步完善功能。每次迭代都要确保代码可运行并通过基本测试。

### 7.1 Phase 1: 项目基础设施
**目标**: 搭建T3项目基础，确保开发环境可正常运行

#### 任务1.1: T3项目初始化
- 使用create-t3-app初始化项目
- 配置TypeScript严格模式
- 设置pnpm包管理
- 配置Prisma + SQLite
- 设置基础的ESLint和Prettier

#### 任务1.2: 基础架构配置
- 配置NextAuth.js简单认证
- 实现固定账号登录 (admin/a2885828)
- 设置基础的tRPC路由结构
- 配置Tailwind CSS
- 创建基础布局组件

#### 任务1.3: 固定账号认证实现
- 配置NextAuth.js CredentialsProvider
- 实现固定账号密码验证 (admin/a2885828)
- 设置会话管理和保护路由
- 创建登录页面和认证逻辑

**认证实现方式**:
- 使用NextAuth.js v5的CredentialsProvider
- 在`src/server/auth/config.ts`中配置认证逻辑
- 验证逻辑: 硬编码检查用户名密码是否匹配配置文件中的值
- 会话管理: 使用NextAuth.js默认会话机制
- 路由保护: 使用NextAuth.js中间件保护管理页面

**验收标准**: ✅ 已完成 - 项目可启动，登录功能正常，基础页面可访问

### 7.2 Phase 2: 核心爬虫引擎 (代码分析) - 已完成
**目标**: ✅ 已完成 - 实现基础的Playwright代码分析爬虫功能，优先支持推文爬取

#### 任务2.1: Playwright集成 ✅
- ✅ 安装和配置Playwright (仅Chromium)
- ✅ 实现基础浏览器管理类 (`src/server/core/browser/manager.ts`)
- ✅ 配置页面超时时间 (默认30秒，可配置)
- ✅ 实现基础的CSS选择器功能 (优先，XPath后续扩展)

#### 任务2.2: 代码分析爬虫核心 ✅
- ✅ 设计爬虫基础类接口
- ✅ 实现CSS选择器解析 (`src/server/core/spider/selectors/twitter.ts`)
- ✅ 添加数据提取逻辑 (文本、链接、图片URL)
- ✅ 实现点击和滚动交互功能
- ✅ 添加随机延迟机制 (1-3秒可配置)
- ✅ 实现基础错误处理

#### 任务2.3: 爬虫任务系统 ✅
- ✅ 设计任务数据模型 (Prisma schema)
- ✅ 实现任务创建和执行 (`src/server/core/tasks/executor.ts`)
- ✅ 添加任务状态管理
- ✅ 实现简单的任务队列 (最大3个并发，可配置)
- ✅ 添加重试机制 (延迟重试，可配置开关和延迟时间)
- ✅ 保留完整历史记录

**任务队列实现方式 (简单方案)**:
- 使用内存数组作为任务队列，无需持久化
- 服务器重启后任务丢失 (对个人项目可接受)
- 实现位置: `src/server/core/tasks/queue.ts`
- 基本结构:
```typescript
interface TaskQueue {
  pending: SpiderTask[];
  running: Map<string, SpiderTask>;
  completed: SpiderTask[];
  failed: SpiderTask[];
}

class SimpleTaskQueue {
  private queue: TaskQueue;
  
  addTask(task: SpiderTask): void;
  getNextTask(): SpiderTask | null;
  updateTaskStatus(taskId: string, status: TaskStatus): void;
  getTaskById(taskId: string): SpiderTask | null;
}
```

**Phase 2 开发决策备忘**:
- **优先场景**: 推文爬取功能
- **数据提取类型**: 文本（包括链接）、图片URL
- **选择器支持**: 优先CSS选择器，XPath作为后续扩展
- **页面交互**: 支持点击和滚动，暂不支持表单交互
- **并发控制**: 默认3个并发任务，可配置
- **延迟策略**: 随机延迟1-3秒，可配置范围
- **重试机制**: 延迟重试，支持开关和时间配置
- **浏览器管理**: 任务结束立即关闭实例，不需要健康检查
- **任务执行**: 按顺序执行，不支持优先级
- **历史记录**: 始终保持完整历史记录
- **分页和链接追踪**: 根据实际开发情况决定

**验收标准**: ✅ 已完成 - 可以通过API提交简单爬取任务并获得结果

---

## Phase 2.1 Twitter List爬虫完整开发方案 - 已完成

### 🎯 功能目标 ✅
✅ 已完成 - 实现Twitter List推文爬取功能，包括数据提取、存储、任务管理和前端界面。

### 📊 数据流程设计 ✅

```
用户输入List ID → 创建爬虫任务 → 任务队列 → Playwright执行 → 数据解析 → 存储数据库 → 更新任务状态
```

### 🏗️ 系统架构 ✅

#### **核心组件** ✅
1. **浏览器管理器** (`src/server/core/browser/manager.ts`) ✅
2. **Twitter选择器解析器** (`src/server/core/spider/selectors/twitter.ts`) ✅
3. **任务执行引擎** (`src/server/core/tasks/executor.ts`) ✅
4. **数据存储服务** (`src/server/core/data/storage.ts`) ✅
5. **前端管理界面** (3个页面) ✅

#### **技术特征识别** ✅

**Retweet识别逻辑** ✅:
```typescript
// 判断推文是否为Retweet的两个条件（AND关系）
const isRetweet = 
  // 条件1: 包含转发图标SVG
  !!tweet.querySelector('svg[viewBox="0 0 24 24"] path[d*="M4.75 3.79l4.603 4.3"]') &&
  // 条件2: 包含"reposted"文本
  !!tweet.querySelector('[data-testid="socialContext"]')?.textContent?.includes('reposted');
```

**滚动加载检测** ✅:
```typescript
// 智能滚动策略，支持无效滚动检测
const scrollDistance = afterScrollPosition - beforeScrollPosition;
if (scrollDistance < 100) {
  consecutiveNoScrollCount++;
}
```

### 🔧 开发任务分解 ✅

#### **Phase 2.1.1: 核心爬虫引擎** ✅

**任务2.1.1.1: Playwright基础集成** ✅
- ✅ 创建 `BrowserManager` 类
- ✅ 实现页面导航和等待逻辑
- ✅ 添加健康检查机制

**任务2.1.1.2: Twitter选择器实现** ✅
- ✅ 创建 `TwitterSelector` 类
- ✅ 实现推文数据提取方法
- ✅ 添加Retweet识别逻辑
- ✅ 实现多图片URL提取

**任务2.1.1.3: 滚动加载管理** ✅
- ✅ 实现智能滚动策略
- ✅ 添加新内容检测
- ✅ 实现停止条件判断

#### **Phase 2.1.2: 数据存储和任务管理** ✅

**任务2.1.2.1: 数据库操作** ✅
- ✅ 实现Tweet和SpiderTask模型的CRUD
- ✅ 添加去重查询逻辑
- ✅ 实现批量数据插入

**任务2.1.2.2: 任务执行系统** ✅
- ✅ 创建 `TaskExecutor` 类
- ✅ 实现任务状态管理
- ✅ 添加错误处理和重试
- ✅ 集成任务队列机制

#### **Phase 2.1.3: API接口开发** ✅

**任务2.1.3.1: tRPC路由实现** ✅
```typescript
// 任务管理路由
tasks.create             // 创建Twitter List爬取任务 ✅
tasks.list               // 获取任务列表 ✅
tasks.getById            // 获取任务详情 ✅
tasks.cancel             // 取消任务 ✅
tasks.delete             // 删除任务 ✅
tasks.retry              // 重试任务 ✅

// 数据查询路由  
tweets.getByTaskId       // 根据任务ID获取推文 ✅
tweets.getByListId       // 根据List ID获取推文 ✅
tweets.list              // 获取所有推文（分页） ✅
tweets.search            // 搜索推文 ✅
tweets.getTrending       // 获取热门推文 ✅
tweets.getStats          // 获取推文统计 ✅
tweets.getUserRanking    // 获取用户排行榜 ✅
tweets.export            // 导出推文数据 ✅
tweets.delete            // 删除推文 ✅
tweets.batchDelete       // 批量删除推文 ✅
```

#### **Phase 2.1.4: 前端界面开发** ✅

**页面1: 任务列表管理** (`/tasks`) ✅
- ✅ 任务状态实时显示
- ✅ 任务详情查看
- ✅ 创建、取消、删除、重试操作
- ✅ 数据查看入口

**页面2: 推文数据展示** (`/tweets`) ✅
- ✅ 数据表格展示
- ✅ 筛选和搜索功能
- ✅ 数据导出功能
- ✅ 分页和排序

**页面3: 系统仪表板** (`/dashboard`) ✅
- ✅ 系统状态展示
- ✅ 统计数据可视化
- ✅ 最近任务和推文预览

**页面4: API文档** (`/api-docs`) ✅
- ✅ 完整的API接口文档
- ✅ 使用示例和数据模型
- ✅ 错误代码说明

### 🚀 最新完成的重要功能

#### **2024年全局重复检测和滚动优化** ✅
- ✅ 全局任务级别重复检测 (processedTweetIds)
- ✅ 区分任务内重复 vs 数据库重复
- ✅ 只有数据库重复才触发连续退出机制
- ✅ 新增页面滚动效果检测
- ✅ 连续无效滚动自动终止任务

#### **外部REST API接口** ✅
- ✅ 创建爬取任务 API (`POST /api/external/tasks`)
- ✅ 获取任务列表 API (`GET /api/external/tasks`)
- ✅ 获取任务详情 API (`GET /api/external/tasks/{id}`)
- ✅ 获取任务数据 API (`GET /api/external/data/{id}`)
- ✅ API Key认证机制

### 7.3 Phase 3: Web管理界面 - 已完成 ✅
**目标**: ✅ 已完成 - 实现简约的管理后台界面

#### 任务3.1: 导航和布局 ✅
- ✅ 响应式导航组件 (`src/components/navigation.tsx`)
- ✅ 统一的页面布局和样式
- ✅ 用户认证状态显示

#### 任务3.2: 任务管理界面 ✅
- ✅ 任务创建表单和验证
- ✅ 任务列表实时显示
- ✅ 任务操作（取消、删除、重试）

#### 任务3.3: 数据查看界面 ✅
- ✅ 推文数据表格展示
- ✅ 高级筛选和搜索
- ✅ 数据导出和批量操作

**验收标准**: ✅ 已完成 - 管理界面功能完整，操作流畅，界面简约

### 7.4 Phase 4: 高级功能完善 - 已完成 ✅
**目标**: ✅ 已完成 - 完善系统功能，提高稳定性

#### 任务4.1: 数据管理优化 ✅
- ✅ 实现数据去重机制
- ✅ 添加数据索引优化
- ✅ 实现数据导出功能（JSON/CSV）
- ✅ 添加基础统计功能

#### 任务4.2: 系统稳定性 ✅
- ✅ 完善错误处理机制
- ✅ 添加详细日志记录
- ✅ 实现浏览器资源管理
- ✅ 添加任务结束原因追踪

#### 任务4.3: 外部API接口 ✅
- ✅ 实现REST API供外部调用
- ✅ 完善API文档页面
- ✅ 实现API Key认证
- ✅ 标准化响应格式

**验收标准**: ✅ 已完成 - 系统稳定运行，支持外部系统集成

---

## Phase 2.2 核心系统优化规划

### 🔧 已识别的重点优化项

#### **优化项1: 浏览器实例池管理 (建议优化)**
**当前状态**: 每个爬虫任务启动独立的浏览器实例
**优化目标**: 实现浏览器实例池，多任务复用同一浏览器
**预期收益**: 
- 显著降低内存占用（单实例约200MB -> 共享池约50MB/任务）
- 提升任务启动速度（无需重复启动浏览器）
- 支持更高并发数量

**实施方案**:
```typescript
// src/server/core/browser/pool.ts
class BrowserPool {
  private instances: Map<string, BrowserInstance>;
  private maxInstances: number = 5;
  private getAvailableInstance(): Promise<BrowserInstance>;
  private releaseInstance(instanceId: string): void;
}
```

#### **优化项2: 数据库查询效率优化 (建议优化)**
**当前状态**: 部分API在内存中过滤大量数据
**问题**: 
- 推文搜索：先获取全部数据再内存过滤
- 单条推文查询：查询1000条记录再筛选
**优化目标**: 数据库层面精确查询
**实施方案**:
```typescript
// 直接数据库搜索
async searchTweets(query: string): Promise<Tweet[]> {
  return db.tweet.findMany({
    where: {
      OR: [
        { content: { contains: query } },
        { userNickname: { contains: query } },
        { userUsername: { contains: query } }
      ]
    }
  });
}
```

#### **优化项3: 任务持久化与恢复机制 (后续优化)**
**当前状态**: 内存任务队列，服务重启丢失
**优化目标**: 数据库持久化任务状态，支持服务重启恢复
**实施方案**:
- 任务状态实时同步到数据库
- 服务启动时检查未完成任务
- 支持任务暂停/恢复功能

#### **优化项4: 选择器适配性增强 (持续优化)**
**当前状态**: 硬编码CSS选择器，Twitter更新时易失效
**风险**: Twitter前端更新导致爬虫失效
**现有应对**: 选择器集中管理，详细注释
**后续增强**:
- 多重备选选择器策略
- 自动检测选择器有效性
- 选择器版本管理机制

### 7.5 Phase 5: 视觉分析爬虫预留 (第二阶段开发)
**目标**: 为视觉分析爬虫预留架构空间

#### 任务5.1: 架构预留设计
- 设计视觉爬虫接口规范
- 预留Midscene集成入口
- 创建视觉爬虫基础类(空实现)
- 在管理界面预留视觉爬虫选项

#### 任务5.2: 扩展接口设计
- 定义Playwright + Midscene集成接口
- 设计视觉识别任务流程
- 预留视觉配置数据结构
- 创建扩展点文档

**验收标准**: 架构支持后续视觉爬虫扩展，接口清晰

### 7.6 开发环境配置支持
**目标**: 为开发者提供完整的环境设置和一键启动

#### 环境设置脚本 (`scripts/setup-dev.ts`)
- **环境检测**: 自动检测Node.js (>=18) 和 pnpm 安装状态
- **依赖安装**: 自动执行 `pnpm install`
- **数据库初始化**: 自动执行 `prisma generate && prisma db push`
- **Playwright依赖**: 自动安装浏览器依赖 `npx playwright install chromium`
- **环境变量**: 自动生成 `.env.local` 文件
- **目录创建**: 自动创建 `data/database`, `data/logs`, `data/browser-data` 目录

#### VS Code开发工具配置
- **推荐扩展** (`.vscode/extensions.json`):
  - ESLint
  - Prettier - Code formatter
  - Prisma
  - Tailwind CSS IntelliSense
  - Playwright Test for VSCode
  - TypeScript Importer
- **调试配置** (`.vscode/launch.json`):
  - Next.js开发服务器调试
  - Playwright测试调试
- **工作区设置** (`.vscode/settings.json`):
  - TypeScript严格模式
  - 自动格式化配置

#### 全局配置文件 (`src/lib/config.ts`)
```typescript
export const config = {
  port: 3067,
  playwright: {
    browser: 'chromium' as const,
    headless: true, // 可切换为false进行调试
    userDataDir: './data/browser-data',
  },
  database: {
    url: 'file:./data/database/unicatcher.db',
  },
  auth: {
    username: 'admin',
    password: 'a2885828',
  },
} as const;
```

#### 开发启动说明 (`README.md`)
```bash
# 1. 一键环境设置
pnpm run setup-dev

# 2. 启动开发服务器
pnpm run dev

# 3. 访问管理界面
http://localhost:3067
```

**验收标准**: 新开发者通过 `pnpm run setup-dev` 即可完成所有环境配置

## 8. 结论与后续安排

### 8.1 技术方案总结

本项目采用T3 Stack全栈TypeScript技术方案，具有以下优势：
- **类型安全**: 端到端TypeScript，减少运行时错误
- **开发效率**: tRPC提供类型安全的API，Prisma提供类型安全的数据库操作  
- **现代技术栈**: Next.js 14 + React 18，性能优异
- **简约设计**: Tailwind CSS实现轻量级管理界面
- **扩展性良好**: 架构预留视觉分析爬虫扩展空间

### 8.2 关键设计决策

1. **优先代码分析爬虫**: 第一阶段专注Playwright + TypeScript实现
2. **模板只读设计**: 采集规则模板仅展示，避免复杂编辑逻辑
3. **本地SQLite存储**: 降低部署复杂度，预留Supabase迁移
4. **AI协助开发**: 增量式开发，每个模块都要可运行验证
5. **架构预留设计**: 为视觉分析爬虫预留清晰的扩展接口

### 8.3 当前开发状态

基于AI vibe coding开发模式，项目开发已完成：

**✅ 第一步**: 项目初始化 (T3 Stack) - 已完成
**✅ 第二步**: 基础认证和路由 - 已完成  
**✅ 第三步**: Playwright爬虫核心功能 - 已完成
**✅ 第四步**: 简约管理界面 - 已完成
**✅ 第五步**: 系统集成和优化 - 已完成
**✅ 第六步**: 外部REST API - 已完成
**✅ 第七步**: 完整API文档 - 已完成

### 8.4 系统当前能力

#### **✅ 核心爬虫功能**
- 完整的Twitter List推文爬取
- 智能滚动和重复检测
- 转推和回复推文过滤
- 图片URL提取和完整文本展开
- 全局任务级别重复处理

#### **✅ 数据管理**
- SQLite数据库存储
- 推文数据CRUD操作
- JSON/CSV格式导出
- 批量操作支持

#### **✅ 任务管理**
- 任务创建、监控、取消
- 任务状态实时追踪
- 错误处理和重试机制
- 任务结束原因分析

#### **✅ Web管理界面**
- 响应式管理后台
- 任务和数据管理
- 搜索和筛选功能
- 系统状态仪表板

#### **✅ API接口**
- 完整的tRPC内部API
- RESTful外部API
- API Key认证
- 详细的API文档

### 8.5 后续扩展方向

- **浏览器实例池管理**: 优化内存使用和性能
- **数据库查询优化**: 提升大数据量查询效率
- **任务持久化**: 支持服务重启恢复
- **视觉分析爬虫**: Midscene AI集成（第二阶段）
- **多站点支持**: 扩展到其他社交媒体平台

---

**项目代号**: UniCatcher  
**文档版本**: v3.0 (生产就绪版本)  
**开发模式**: AI Vibe Coding  
**技术栈**: T3 Stack (Next.js + TypeScript + tRPC + Prisma)  
**当前状态**: ✅ 生产就绪 - 核心功能完整，系统稳定运行  
**下一阶段**: 视觉分析爬虫 + 性能优化 