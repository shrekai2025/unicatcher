一、数据收集与预处理（详细展开）

  1.1 数据结构设计

  1.1.1 核心数据模型

  推文实体（Tweet Entity）
  {
    tweet_id: 唯一标识符,
    content: {
      raw_text: "原始文本内容",
      cleaned_text: "清洗后文本",
      text_length: 字符数,
      word_count: 分词后词数
    },

    temporal: {
      publish_time: ISO8601时间戳,
      publish_hour: 0-23,
      publish_day_of_week: 0-6,
      time_category: "通勤时间/工作时间/晚间/深夜/周末"
    },

    engagement: {
      likes: 点赞数,
      retweets: 转发数,
      comments: 评论数,
      views: 浏览量,
      data_collection_time: 数据采集时间（用于计算时间衰减）,
      hours_since_publish: 发布后经过小时数
    },

    metadata: {
      is_original: true/false,
      has_media: true/false,
      media_type: "none/image/video/link",
      has_hashtag: true/false,
      has_mention: true/false,
      is_thread: true/false,
      thread_position: 线索中的位置
    },

    parsed_elements: {
      hashtags: ["#标签1", "#标签2"],
      mentions: ["@用户1"],
      urls: ["链接1"],
      emojis: ["😊", "👍"],
      emoji_count: 2,
      emoji_positions: ["start", "end"]
    }
  }

  1.1.2 扩展数据模型

  用户画像（User Profile）
 *暂不分析用户画像

  评论数据（可选，深度分析用）
  *暂不分析评论

  1.2 数据清洗规则

  1.2.1 文本预处理流程

  Step 1: 内容分离
  原始推文 → 判断是否转发

*暂不判断，全部视为原创true

  Step 2: 元素提取与占位
  FOR EACH 推文:
    1. 提取所有@mentions → 替换为[MENTION]
    2. 提取所有#hashtags → 保留但单独记录
    3. 提取所有URLs → 替换为[LINK]
    4. 提取所有emojis → 保留但单独记录位置

  示例：
  原文: "今天在@咖啡店 发现了一个好工具 https://... 😊 #效率工具"
  处理后: "今天在[MENTION] 发现了一个好工具 [LINK] 😊"
  记录: hashtags=["效率工具"], emojis=["😊"], mentions=["咖啡店"]

  Step 3: 噪声过滤
  过滤规则：
  - 删除纯转发（无自己评论的RT）
  - 删除纯链接推文（内容<10字且仅含链接）
  - 删除重复推文（相似度>90%）

  相似度计算（余弦相似度）：
  similarity = (A·B) / (||A|| × ||B||)
  其中A、B为两条推文的TF-IDF向量

  1.2.2 分词与词性标注

  中文分词方案
  使用结巴分词（jieba）+ 自定义词典

  自定义词典构建：
  1. 从所有推文中提取2-4字高频组合
  2. 计算互信息（Mutual Information）

  MI(x,y) = log[P(x,y) / (P(x)×P(y))]

  3. MI > 阈值（如8.0）→ 加入词典

  示例：
  "产品经理" MI=12.3 → 作为一个词
  "的时候" MI=3.2 → 不作为词

  词性分配
  使用jieba.posseg进行词性标注

  关注词性：
  - n (名词): 主题词
  - v (动词): 行动词
  - a (形容词): 描述词
  - d (副词): 语气词
  - m (数词): 数据支撑
  - r (代词): 人称使用习惯

  计算各词性占比：
  词性占比 = 该词性词数 / 总词数

  1.2.3 句子切分与标注

  句子边界识别
  分句符号优先级：
  1. 强分隔：。！？\n（换行）
  2. 弱分隔：；，……

  规则：
  - 连续句号/感叹号视为一个分隔符（"。。。"算1次）
  - 省略号后如跟随句号，合并处理
  - emoji紧跟标点时，emoji归属前句

  示例：
  "今天很开心😊。明天继续努力！"
  → 句子1: "今天很开心😊。" (带emoji结尾)
  → 句子2: "明天继续努力！" (感叹句)

  句子类型分类
  陈述句判定：结尾 = 。或,或无标点
  疑问句判定：包含 "吗/呢/么/?" 或 结尾=？
  感叹句判定：结尾 = ！ 或 包含 "真/太/好"等强情感词
  祈使句判定：开头 = 动词 或 包含 "请/让/要"

  句型分布 = {
    declarative: X%,   # 陈述
    interrogative: X%, # 疑问
    exclamatory: X%,   # 感叹
    imperative: X%     # 祈使
  }

  1.2.4 特殊元素标准化

  Emoji处理
  位置分类：
  - start: 出现在前20%字符
  - middle: 出现在20%-80%字符
  - end: 出现在后20%字符

  功能分类（通过emoji库）：
  - emotion: 😊😢😂🥰 (表情)
  - gesture: 👍👏🙏💪 (手势)
  - object: 📱💡🎯📚 (物品)
  - symbol: ✅❌⭐💯 (符号)

  密度计算：
  emoji_density = emoji总数 / 推文总数
  position_preference = {
    start: 出现次数/总emoji数,
    middle: ...,
    end: ...
  }

  标点符号分析
  关键标点统计：
  - 感叹号密度 = ！数量 / 句子数
  - 问号密度 = ？数量 / 句子数
  - 省略号密度 = ……数量 / 推文数
  - 顿号使用率 = 含、的推文数 / 总推文数
  - 冒号使用率 = 含：的推文数 / 总推文数
  - 括号使用率 = 含（）的推文数 / 总推文数

  标点风格判定：
  IF 感叹号密度 > 0.3 → 热情型
  IF 省略号密度 > 0.5 → 留白型
  IF 问号密度 > 0.2 → 互动型

  1.3 数据质量控制

  1.3.1 样本量评估

  最小样本需求
  置信区间计算（95%置信度）：

  n = (Z² × p × (1-p)) / E²

  其中：
  - Z = 1.96 (95%置信度)
  - p = 0.5 (最保守估计)
  - E = 0.05 (误差范围5%)

  n = (1.96² × 0.5 × 0.5) / 0.05² ≈ 384

  建议最小样本：
  - 推文数量：≥100条（基础分析）
  - 推文数量：≥300条（可靠分析）
  - 推文数量：≥500条（精细分析）

  按主题最小样本：
  - 每个主要主题：≥30条
  - 每个次要主题：≥10条

  1.3.2 数据完整性检查

*暂不检测

  1.3.3 异常值检测

  互动数据异常检测（使用箱线图法）
  FOR 点赞数、转发数、评论数:

    Q1 = 第25百分位数
    Q3 = 第75百分位数
    IQR = Q3 - Q1 (四分位距)

    下界 = Q1 - 1.5×IQR
    上界 = Q3 + 1.5×IQR

    IF 某推文数据 > 上界 → 标记为"异常高"
    IF 某推文数据 < 下界 → 标记为"异常低"

  处理策略：
  - 异常高值：单独分析（可能是爆款）
  - 异常低值：检查是否为数据错误
  - 保留异常值，但在计算平均值时使用中位数

  文本长度异常检测
  IF 推文长度 < 5字 → 标记"过短"（可能无分析价值）
  IF 推文长度 > 平台限制×1.5 → 标记"异常"（可能是长图文）

  分布检查：
  使用核密度估计（KDE）查看长度分布
  IF 出现明显双峰 → 说明有两种风格（短推文、长推文）

  1.4 数据增强

  1.4.1 时间特征工程

*暂不分析

  1.4.2 互动数据归一化

*暂不分析

  1.4.3 主题预标注（粗分类）

  基于关键词的初步分类
  预定义主题词典：
  {
    "工作": ["项目", "团队", "会议", "deadline", "汇报", "方案"],
    "生活": ["早餐", "运动", "电影", "周末", "旅行", "美食"],
    "观点": ["认为", "觉得", "应该", "其实", "发现", "思考"],
    "知识": ["学习", "分享", "教程", "推荐", "方法", "技巧"],
    "情感": ["开心", "难过", "焦虑", "感动", "幸福", "累"]
  }

  匹配算法：
  FOR EACH 推文:
    topic_scores = {}
    FOR EACH 主题:
      score = Σ(关键词在推文中出现次数) / 该主题关键词总数
      topic_scores[主题] = score

    primary_topic = max(topic_scores)
    IF max_score < 0.1 → 标记为"其他"

  注意：这只是初步分类，精细分类由LLM完成

  ---
  二、风格分析框架（详细展开）

  2.1 语言风格维度

  2.1.1 词汇层面分析

  A. 词汇丰富度（Lexical Diversity）

  方法一：类型-标记比（TTR）
  基础TTR = 独特词数（Types） / 总词数（Tokens）

  问题：受文本长度影响大

  改进：标准化TTR（STTR）
  - 将所有推文拼接
  - 每100词计算一次TTR
  - 取平均值

  STTR = (Σ TTR_每100词) / 段数

  解释：
  - STTR < 0.4: 词汇重复度高，风格单一
  - 0.4 ≤ STTR < 0.6: 适中，有一定变化
  - STTR ≥ 0.6: 词汇丰富，表达多样

  方法二：Yule's K（更稳定的指标）
  V = 独特词总数
  N = 总词数
  V_i = 出现i次的词的种类数

  K = 10000 × (Σ(i² × V_i) - N) / N²

  解释：
  - K < 100: 词汇极度丰富
  - 100 ≤ K < 200: 词汇较丰富
  - K ≥ 200: 词汇重复度高

  优势：不受文本长度影响

  B. 词汇复杂度

  平均词长
  avg_word_length = Σ(每个词的字符数) / 总词数

  中文特征：
  - < 1.5字/词: 多用单字词，简洁风格
  - 1.5-2.0字/词: 正常
  - > 2.0字/词: 偏好成语、专业术语

  罕见词使用率
  构建通用词频表（如现代汉语常用词表前5000）

  rare_word_ratio = 不在常用词表的词数 / 总词数

  分层统计：
  - 常用词（前1000）使用率
  - 次常用词（1000-3000）使用率
  - 低频词（3000-5000）使用率
  - 罕见词（5000+）使用率

  高罕见词率 → 专业性强或故意使用生僻表达

  C. 高频词分析

  TF-IDF提取特征词
  TF-IDF(词w, 推文d) = TF(w,d) × IDF(w)

  TF(w,d) = 词w在推文d中出现次数 / 推文d总词数

  IDF(w) = log(总推文数 / 包含词w的推文数)

  流程：
  1. 计算所有词的TF-IDF
  2. 对每条推文，取TOP3高分词
  3. 统计所有推文中TOP词的频率
  4. 输出TOP50作为"风格标志词"

  示例输出：
  ["思考"(45次), "发现"(38次), "产品"(32次), ...]

  词云分层
  一级词云（出现>20%推文）：核心主题词
  二级词云（出现10-20%推文）：常用表达
  三级词云（出现5-10%推文）：辅助词汇

  FOR EACH 层级:
    计算词性分布
    提取搭配模式（如"产品"常与"思考"搭配）

  D. 词性分布特征

  基础词性统计
  使用jieba.posseg标注后：

  名词占比 = 名词总数 / 总词数
  动词占比 = 动词总数 / 总词数
  形容词占比 = 形容词总数 / 总词数
  副词占比 = 副词总数 / 总词数

  风格判定：
  - 高名词比（>0.4）：信息密集型，多陈述事实
  - 高动词比（>0.3）：行动导向型，强调过程
  - 高形容词比（>0.15）：描述性强，注重细节
  - 高副词比（>0.1）：语气丰富，口语化

  名动比（Noun-Verb Ratio）
  N/V ratio = 名词总数 / 动词总数

  解释：
  - N/V > 1.5: 名词化风格，正式、学术
  - 1.0 < N/V < 1.5: 平衡
  - N/V < 1.0: 动作导向，动态、口语化

  示例：
  "我在思考产品逻辑" (N/V=2/1=2.0, 名词化)
  "我想了想，决定改改产品" (N/V=1/3=0.33, 动作化)

  代词使用模式
  统计人称代词：

  第一人称（我、我们、咱）使用率
  第二人称（你、您、你们）使用率
  第三人称（他、她、它们）使用率

  人称偏好 = 使用最多的人称

  解释：
  - 高"我"：个人经验分享型
  - 高"你"：对话式、互动型
  - 高"我们"：共同体意识
  - 少代词：客观陈述型

  2.1.2 句式层面分析

  A. 句长统计

  基础指标
  FOR EACH 推文:
    sentences = 按标点切分句子
    FOR EACH 句子:
      计算字符数（不含标点）

  句长数据集 = [s1_len, s2_len, ..., sn_len]

  平均句长 = Σ(句长) / 句子总数
  句长中位数 = median(句长数据集)
  句长标准差 = std(句长数据集)

  句长分布分析
  短句：< 10字
  中句：10-20字
  长句：20-30字
  超长句：> 30字

  分布比例：
  short_ratio = 短句数 / 总句数
  medium_ratio = 中句数 / 总句数
  long_ratio = 长句数 / 总句数
  extra_long_ratio = 超长句数 / 总句数

  句式风格判定：
  IF short_ratio > 0.6 → "短句风格"（有力、节奏快）
  IF medium_ratio > 0.5 → "中等句式"（平衡）
  IF long_ratio > 0.3 → "长句风格"（论证充分）
  IF std(句长) < 5 → "句式单一"
  IF std(句长) > 10 → "句式多变"

  句长变化系数（CV）
  CV = 句长标准差 / 平均句长

  解释：
  - CV < 0.3: 句长高度统一（如都是短句）
  - 0.3 ≤ CV < 0.6: 有一定变化
  - CV ≥ 0.6: 句式富于变化

  高CV值 → 长短句交错，节奏感强

  B. 句型分类与占比

  句型自动识别
  陈述句识别：
  - 结尾：。或 , 或无标点
  - 不含疑问词
  - 不含强烈情感词+！

  疑问句识别：
  - 结尾：？
  - 或包含：吗、呢、么、什么、怎么、为什么、哪里
  - 句式模式："...吗？" "是不是..." "有没有..."

  感叹句识别：
  - 结尾：！
  - 或包含：真、太、好、多么 + 形容词
  - 情感词 + 强调副词

  祈使句识别：
  - 开头动词
  - 包含：请、让、要、别、不要、应该
  - 模式："来..." "去..." "试试..."

  句型分布矩阵
           | 短句 | 中句 | 长句 |
  ---------|------|------|------|
  陈述句   |  20  |  35  |  10  |
  疑问句   |  8   |  12  |  2   |
  感叹句   |  15  |  5   |  1   |
  祈使句   |  3   |  2   |  0   |

  交叉分析：
  - "短句+感叹句"占比高 → 情绪表达直接
  - "长句+陈述句"占比高 → 论证型风格
  - "短句+疑问句"占比高 → 互动引导型

  C. 标点符号深度分析

  标点密度矩阵
  FOR EACH 标点类型:

    使用频率 = 该标点出现推文数 / 总推文数
    使用密度 = 该标点总数 / 总推文数
    位置分布 = [句首, 句中, 句尾] 占比

  关键标点：
  1. 感叹号！
     - 密度 = 每条推文平均几个
     - 连用率 = "!!"或"!!!"出现比例
     - 单独使用 vs 混用（"！？"）

  2. 问号？
     - 密度
     - 连用率（"？？"）
     - 反问标记（"？！"）

  3. 省略号……
     - 密度
     - 位置（句中留白 vs 句尾悬念）

  4. 破折号——
     - 使用率（解释说明风格）

  5. 顿号、
     - 使用率（并列表达习惯）

  6. 冒号：
     - 使用率（总分结构使用）

  7. 引号""
     - 使用率（引用、强调习惯）

  8. 括号（）
     - 使用率（补充说明习惯）

  标点风格综合评分
  情感强度分 = (感叹号密度×2 + 问号密度×1.5) / 2
  留白风格分 = 省略号密度×10
  严谨风格分 = (冒号使用率 + 引号使用率 + 破折号使用率) / 3
  口语化分 = (感叹号密度 + 省略号密度 - 分号使用率) / 2

  标点风格画像：
  IF 情感强度分 > 0.5 → "情感充沛型"
  IF 留白风格分 > 0.3 → "意犹未尽型"
  IF 严谨风格分 > 0.2 → "逻辑清晰型"
  IF 口语化分 > 0.4 → "口语化表达"

  2.1.3 修辞特征分析

A. emoji使用
*暂不分析

  B. 语气词与口语化程度

  语气词典构建
  确认类：嗯、嗯嗯、对、是的
  思考类：呃、额、嘛、吧
  情感类：哈哈、哎、唉、啊、呀
  强调类：真的、确实、其实、说实话
  缓和类：可能、大概、或许、差不多

  FOR EACH 语气词:
    frequency = 包含该词的推文数 / 总推文数
    density = 该词总出现次数 / 总推文数

  语气词总使用率 = 含任意语气词的推文数 / 总推文数

  笑声表达分析
  笑声变体：
  哈哈、哈哈哈、哈哈哈哈...
  haha、hahaha...
  hhh、hhhhh...
  😂、🤣

  笑声强度计算：
  强度 = log(连续"哈"或"h"的数量 + emoji数量)

  笑声使用率 = 含笑声表达的推文数 / 总推文数

  高笑声率（>0.3）→ 轻松幽默型风格

  口语化综合得分
  oral_score = (
    语气词使用率 × 0.3 +
    笑声使用率 × 0.2 +
    emoji使用率 × 0.2 +
    反问句占比 × 0.15 +
    (1 - 书面语标记率) × 0.15
  ) × 100

  其中书面语标记 = (因此、然而、综上、鉴于等词使用率)

  分级：
  - oral_score < 30: 正式书面风格
  - 30 ≤ oral_score < 50: 偏书面
  - 50 ≤ oral_score < 70: 口语化
  - oral_score ≥ 70: 强口语化

  C. 修辞手法识别（基于LLM）

  提示词设计
  Prompt模板：
  "
  分析以下推文使用的修辞手法，从以下类型中选择（可多选）：

  1. 比喻：使用"像"、"如同"等，或暗喻
  2. 排比：三个或以上结构相似的句子/短语
  3. 反问：以问句形式表达肯定/否定
  4. 设问：自问自答
  5. 夸张：故意夸大或缩小
  6. 对比：两种事物/观点的对照
  7. 引用：引用名言、俗语、他人话语

  推文：{tweet_content}

  输出JSON格式：
  {
    "修辞手法": ["比喻", "反问"],
    "具体例子": "用'产品像养孩子'比喻产品开发"
  }
  "

  批量处理：
  - 每次发送20条推文
  - 收集所有识别结果
  - 统计各修辞手法使用频率

  修辞手法统计
  FOR EACH 修辞类型:
    使用频率 = 使用该手法的推文数 / 总推文数

  输出：
  {
    "比喻": 15%,
    "反问": 12%,
    "排比": 5%,
    ...
  }

  修辞偏好判定：
  IF "比喻" > 10% → "善用比喻，形象化表达"
  IF "排比" > 5% → "注重气势和节奏"
  IF "反问" > 8% → "引导式互动风格"

  2.2 内容主题维度

  2.2.1 主题分类系统

  一级主题分类（使用LLM）

  提示词设计
  Prompt:
  "
  你是一个社交媒体内容分类专家。请将以下推文分类到一个主要类别：

  类别定义：
  1. 工作/职业：与工作、职业发展、项目、团队相关
  2. 生活日常：日常活动、饮食、运动、休闲
  3. 观点态度：对某事的看法、评论、立场表达
  4. 知识分享：教程、方法论、技巧、推荐
  5. 情感表达：情绪、感受、心情记录
  6. 社交互动：回复、提问、征求意见
  7. 其他：无法归入以上类别

  推文：{tweet_content}

  仅输出类别编号（1-7）。
  "

  批量处理策略：
  - 使用Claude API（成本低、速度快）
  - 每次批处理50条
  - 设置temperature=0（确保一致性）

  二级主题细分（动态提取）
  在一级分类完成后，对每个一级类别：

  Prompt:
  "
  以下是属于'{一级类别}'的推文列表（共{N}条）。
  请识别其中的具体子主题（2-5个），并为每条推文分配子主题。

  推文列表：
  1. {tweet1}
  2. {tweet2}
  ...

  输出JSON格式：
  {
    "子主题列表": ["产品设计", "团队管理", "技术选型"],
    "推文分类": {
      "1": "产品设计",
      "2": "团队管理",
      ...
    }
  }
  "

  优势：
  - 自适应用户实际内容
  - 不预设固定子类别
  - 保留原始语言表达

  主题分布计算
  一级主题分布：
  FOR EACH 一级主题:
    ratio = 该主题推文数 / 总推文数

  输出示例：
  {
    "工作/职业": 35%,
    "观点态度": 25%,
    "生活日常": 20%,
    "知识分享": 15%,
    "情感表达": 5%
  }

  二级主题分布（按一级分组）：
  {
    "工作/职业": {
      "产品设计": 40%,
      "团队协作": 30%,
      "技术选型": 20%,
      "项目管理": 10%
    },
    ...
  }

  主题集中度（熵）：
  H = -Σ(p_i × log2(p_i))

  其中p_i为各主题占比

  解释：
  - H低（<2）：主题高度集中，专注某领域
  - H中（2-3）：主题适度分散
  - H高（>3）：主题非常多样

  2.2.2 内容深度分级

  深度判定标准

  方法一：基于长度和结构
  FOR EACH 推文:

    字数 = 推文字符数
    句数 = 句子数量
    有观点 = 包含"认为/觉得/发现/思考"等
    有论据 = 包含"因为/所以/比如/例如"等
    有数据 = 包含数字/百分比
    有引用 = 包含引号内容

    深度分 = (
      (字数/50) × 0.3 +
      (句数/3) × 0.2 +
      有观点 × 2 +
      有论据 × 2 +
      有数据 × 1.5 +
      有引用 × 1
    )

    IF 深度分 < 2 → "浅层"
    IF 2 ≤ 深度分 < 5 → "中层"
    IF 深度分 ≥ 5 → "深层"

  方法二：基于LLM评估
  Prompt:
  "
  评估以下推文的内容深度（1-5分）：

  1分：日常碎片，无明确信息或观点
  2分：简单陈述，有基本信息但无展开
  3分：有观点或信息，有简单说明
  4分：有结构化论述，包含案例或论据
  5分：深度分析，有完整论证或系统性思考

  推文：{tweet_content}

  仅输出分数（1-5）。
  "

  映射到三级：
  1-2分 → 浅层
  3分 → 中层
  4-5分 → 深层

  深度分布统计
  浅层占比 = 浅层推文数 / 总数
  中层占比 = 中层推文数 / 总数
  深层占比 = 深层推文数 / 总数

  平均深度指数 = (浅层数×1 + 中层数×2 + 深层数×3) / 总数

  解释：
  - 指数 < 1.5: 以碎片化内容为主
  - 1.5 ≤ 指数 < 2.2: 平衡型
  - 指数 ≥ 2.2: 深度内容为主

  按主题交叉分析：
  {
    "工作/职业": {
      "浅层": 20%, "中层": 50%, "深层": 30%
    },
    "生活日常": {
      "浅层": 60%, "中层": 35%, "深层": 5%
    }
  }

  洞察：某些主题适合深度（工作），某些适合轻松（生活）

  2.2.3 内容结构模式

  结构元素识别
  FOR EACH 推文:

    有开头引入 = (
      以问句开头 OR
      以场景描述开头 OR
      以"今天/刚刚/最近"等时间词开头
    )

    有主体内容 = (
      字数 > 30 AND
      包含完整句子
    )

    有结尾收束 = (
      最后一句为疑问/总结/号召 OR
      以emoji结尾 OR
      以省略号结尾（留白）
    )

    结构完整度 = (有开头 + 有主体 + 有结尾) / 3

  开头模式分类
  通过LLM识别开头类型：

  Prompt:
  "
  判断以下推文的开头方式（选择一个）：

  A. 疑问式：以问句开头
  B. 陈述式：直接陈述事实/观点
  C. 场景式：描述具体场景
  D. 情感式：直接表达情绪
  E. 引用式：引用他人话语或名言
  F. 数据式：以数字/统计开头
  G. 其他

  推文：{tweet_content}

  输出字母（A-G）。
  "

  统计分布：
  {
    "疑问式": 25%,
    "场景式": 30%,
    "陈述式": 35%,
    ...
  }

  结尾模式分类
  类似的，识别结尾类型：

  A. 开放提问：以问句结束
  B. 总结陈述：归纳总结
  C. 行动号召：呼吁尝试/关注
  D. 情感共鸣：情绪性结束
  E. 悬念留白：省略号或未完整
  F. 无明确结尾：自然停止

  统计各类型占比

  结构模式组合
  提取高频组合：

  常见模式：
  1. "场景式开头 + 陈述主体 + 开放提问"：出现35次
  2. "疑问式开头 + 论述主体 + 总结陈述"：出现28次
  3. "陈述式开头 + 案例主体 + 悬念留白"：出现22次

  每个模式提取3条代表性推文作为模板

  2.3 互动模式维度

  2.2.4 互动设计元素

  提问频率与类型
  提问率 = 含疑问句的推文数 / 总推文数

  疑问类型分类：
  1. 封闭式问题：能用"是/否"回答
     例："你同意吗？"

  2. 开放式问题：需要详细回答
     例："你怎么看这个问题？"

  3. 选择式问题：提供选项
     例："A还是B更好？"

  4. 反问式问题：不期待回答的修辞性提问
     例："这不是很明显吗？"

  FOR EACH 含疑问句的推文:
    使用LLM判定问题类型

  统计各类型占比：
  {
    "开放式": 45%,
    "反问式": 30%,
    "封闭式": 20%,
    "选择式": 5%
  }

  互动性排序：开放式 > 选择式 > 封闭式 > 反问式

  @他人频率
  mention_rate = 含@符号的推文数 / 总推文数

  mention_density = @总数 / 总推文数

  提及类型：
  - 对话型："@某某 你说得对"
  - 推荐型："推荐关注@某某"
  - 引用型："RT @某某: ..."

  高提及率（>0.3）→ 社交导向型风格
  低提及率（<0.1）→ 独立表达型风格

  话题标签策略
  hashtag_rate = 含#的推文数 / 总推文数

  hashtag_density = #总数 / 总推文数

  标签位置分析：
  - 开头：#话题 + 内容
  - 结尾：内容 + #话题
  - 嵌入：内容中自然嵌入

  标签类型：
  - 通用话题：#生活 #思考
  - 具体话题：#产品设计 #阅读笔记
  - 活动标签：#每日一思 #周末分享

  提取TOP10常用标签

  互动元素密度
  interaction_score = (
    提问率 × 3 +           # 问句权重最高
    mention_rate × 2 +      # 提及次之
    hashtag_rate × 1 +      # 标签最低
    emoji使用率 × 1.5       # emoji增加亲和力
  ) / 7.5 × 100

  分级：
  - 高互动型（>60分）：频繁引导互动
  - 中互动型（30-60分）：适度互动
  - 低互动型（<30分）：单向表达为主

  ---
  三、推文评价系统（详细展开）

  3.1 互动数据评分

  3.1.1 原始互动指标处理

  数据采集时机标准化
  问题：不同推文的互动数据采集时间不同

  解决方案：时间衰减调整

  定义标准采集时间 = 发布后48小时

  FOR EACH 推文:
    actual_hours = 实际采集时间 - 发布时间(小时)
    
    IF actual_hours < 48:
      # 互动数据会继续增长，需要预测
      growth_factor = 48 / actual_hours
      adjusted_engagement = raw_engagement × growth_factor^0.7
      # 0.7为衰减系数，因为增长非线性

    IF actual_hours > 48:
      # 互动数据仍在增长但速度放缓
      decay_factor = 48 / actual_hours
      adjusted_engagement = raw_engagement × decay_factor^0.3
      # 0.3为较小衰减，因为48小时后增长已很慢

    IF 48小时 ≤ actual_hours ≤ 72小时:
      # 最佳采集窗口，无需调整
      adjusted_engagement = raw_engagement

  互动类型权重设计
  不同互动行为的价值权重：

  点赞（Like）：权重 = 1.0
  - 最低成本行为
  - 表示基本认可
  - 基准指标

  转发（Retweet）：权重 = 3.5
  - 中等成本行为
  - 传播价值高
  - 用户愿意背书

  评论（Comment）：权重 = 5.0
  - 最高成本行为
  - 深度互动
  - 产生内容价值

  浏览（View）：权重 = 0.1
  - 最低门槛
  - 曝光指标
  - 用于计算转化率

  收藏（Bookmark，如有）：权重 = 2.5
  - 中高成本
  - 内容价值认可
  - 回访意图

  3.1.2 互动指数计算（详细版）

  基础互动指数（Raw Engagement Score, RES）
  RES = w_like × likes + 
        w_retweet × retweets +
        w_comment × comments +
        w_view × views +
        w_bookmark × bookmarks

  其中：
  w_like = 1.0
  w_retweet = 3.5
  w_comment = 5.0
  w_view = 0.1
  w_bookmark = 2.5

  示例计算：
  推文A：点赞50，转发8，评论3，浏览1000
  RES = 1.0×50 + 3.5×8 + 5.0×3 + 0.1×1000
      = 50 + 28 + 15 + 100
      = 193

  粉丝归一化（Follower-Normalized Score, FNS）
  目的：消除粉丝数差异，使不同时期推文可比

  FNS = (RES / followers_at_publish) × 1000

  其中：
  - followers_at_publish：推文发布时的粉丝数
  - ×1000：放大系数，使数值易读

  粉丝数估算方法（无历史数据时）：
  IF 只知道当前粉丝数:
    # 假设线性增长（保守估计）
    days_ago = (today - publish_date).days
    total_days = (today - account_creation).days

    followers_at_publish = current_followers × (
      1 - (days_ago / total_days) × growth_factor
    )

    growth_factor = 0.5  # 假设历史粉丝数为当前50%

  IF 有多个时间点的粉丝数据:
    # 使用线性插值
    followers_at_publish = np.interp(
      publish_timestamp,
      known_timestamps,
      known_follower_counts
    )

  时间衰减因子（Time Decay Factor, TDF）
  目的：近期数据更可靠，远期数据可能不完整

  使用Sigmoid函数：
  TDF(t) = 1 / (1 + e^(-k × (t - t_optimal)))

  参数设计：
  - t：发布后经过的小时数
  - t_optimal = 48小时（最佳观察点）
  - k = 0.05（衰减速度，可调整）

  函数特性：
  - t = 48时，TDF ≈ 0.5（基准点）
  - t < 48时，TDF < 0.5（数据未完全成熟，降权）
  - t > 48时，TDF > 0.5（数据稳定，增权）
  - t → ∞时，TDF → 1.0（完全成熟）

  实际计算：
  import math
  TDF = 1 / (1 + math.exp(-0.05 * (hours_since_publish - 48)))

  归一化互动分（Normalized Engagement Score, NES）
  NES = FNS × TDF × 100

  为什么×100？
  - 使分数范围更直观（通常0-100）
  - 便于设定阈值和分级

  示例完整计算：
  推文B数据：
  - RES = 193（上面计算的）
  - 发布时粉丝数 = 5000
  - 发布后72小时采集

  步骤：
  1. FNS = (193 / 5000) × 1000 = 38.6

  2. TDF = 1 / (1 + e^(-0.05×(72-48)))
         = 1 / (1 + e^(-1.2))
         = 1 / (1 + 0.301)
         = 0.768

  3. NES = 38.6 × 0.768 × 100 = 2965

  解释：该推文在2965分水平（满分理论上无上限，但通常<10000）

  3.1.3 互动率指标

  基础互动率（Engagement Rate, ER）
  ER = total_engagements / views × 100%

  total_engagements = likes + retweets + comments

  示例：
  views = 10000
  likes = 150
  retweets = 20
  comments = 10

  ER = (150 + 20 + 10) / 10000 × 100% = 1.8%

  行业基准（参考）：
  - ER < 1%：较低
  - 1% ≤ ER < 3%：正常
  - 3% ≤ ER < 6%：良好
  - ER ≥ 6%：优秀

  加权互动率（Weighted Engagement Rate, WER）
  WER = weighted_engagements / views × 100%

  weighted_engagements = (
    likes × 1.0 +
    retweets × 3.5 +
    comments × 5.0
  )

  示例（同上数据）：
  weighted = 150×1 + 20×3.5 + 10×5
           = 150 + 70 + 50
           = 270

  WER = 270 / 10000 × 100% = 2.7%

  解释：考虑行为价值后，实际互动价值相当于2.7%的浏览量

  转化率指标矩阵
  点赞转化率 = likes / views
  转发转化率 = retweets / views
  评论转化率 = comments / views

  点赞转发比 = likes / retweets
  # 高比值（>20）：易获赞但少转发（可能争议性低）
  # 低比值（<10）：高转发价值内容

  评论点赞比 = comments / likes
  # 高比值（>0.1）：引发讨论
  # 低比值（<0.05）：单向认可

  3.2 内容质量评分

  3.2.1 信息密度计算

  实体词密度（Entity Density）
  定义实体词：名词、动词、形容词（排除虚词）

  使用jieba.posseg：
  FOR EACH 推文:
    content_words = [词 for 词, 词性 in 分词结果 
                     if 词性 in ['n', 'v', 'a', 'vn', 'an']]
    
    entity_density = len(content_words) / len(总词数)

  示例：
  推文："我今天在公司开了个会，讨论产品设计方案"
  分词：我/今天/在/公司/开/了/个/会/讨论/产品/设计/方案
  实体词：公司/开/会/讨论/产品/设计/方案 = 7个
  总词数：12个

  entity_density = 7/12 = 0.583

  评分映射：
  IF density < 0.4 → 信息密度低（多虚词、语气词）
  IF 0.4 ≤ density < 0.6 → 中等
  IF density ≥ 0.6 → 信息密集

  信息密度分 = entity_density × 10
  # 映射到0-10分

  关键信息元素识别
  高价值信息元素：

  1. 数据/数字
     识别：正则匹配 \d+%|\d+倍|\d+个|\d+万
     每个数据 +0.5分

  2. 专有名词
     识别：词性为 nr(人名), ns(地名), nt(机构名), nz(专名)
     每个专名 +0.3分

  3. 时间信息
     识别：昨天/今天/上周/2023年等
     每个时间 +0.2分

  4. 因果关系
     识别：因为/所以/导致/由于
     每对因果 +0.5分

  5. 具体案例
     识别：比如/例如/比方说
     每个案例标记 +0.5分

  信息元素分 = min(Σ各元素得分, 5.0)
  # 上限5分，防止过高

  信息密度综合分（0-10分）
  info_density_score = (
    entity_density × 10 × 0.6 +
    信息元素分 × 0.4
  )

  # 确保范围
  info_density_score = min(max(info_density_score, 0), 10)

  3.2.2 情感强度评估

  方法一：基于情感词典
  使用情感词典（如知网情感词典、BosonNLP）：

  FOR EACH 推文:
    positive_words = 匹配积极词
    negative_words = 匹配消极词
    degree_words = 匹配程度副词（很/非常/极其）
    
    positive_score = Σ(积极词得分 × 程度词倍数)
    negative_score = Σ(消极词得分 × 程度词倍数)
    
    sentiment_polarity = (positive_score - negative_score) / 推文长度
    # 归一化到 -1 到 1

    sentiment_intensity = abs(sentiment_polarity)
    # 取绝对值得到强度（0-1）

  示例：
  推文："这个方案真的太好了！"
  - "好"：积极词 +1
  - "真的"：程度词 ×1.5
  - "太"：程度词 ×2
  - 得分：1 × 1.5 × 2 = 3
  - intensity = 3 / 推文长度(标准化)

  方法二：使用LLM评估
  Prompt:
  "
  评估以下推文的情感强度（-10到+10）：

  -10：极度消极（愤怒、绝望）
  -5：明显消极（失望、难过）
  0：中性（平静陈述）
  +5：明显积极（高兴、满意）
  +10：极度积极（狂喜、激动）

  推文：{tweet_content}

  仅输出数字（-10到+10）。
  "

  将输出映射到0-10分：
  emotion_score = (LLM输出 + 10) / 2
  # -10映射到0分，+10映射到10分

  情感强度最终分
  IF 有LLM评估:
    final_emotion_score = LLM评估分
  ELSE:
    final_emotion_score = 词典方法 × 10

  3.2.3 观点独特性评估（仅用LLM）

  评估提示词
  Prompt:
  "
  评估以下推文的观点独特性（0-10分）：

  0-2分：陈述常识或普遍观点，无新意
  3-4分：常见观点，表达方式略有不同
  5-6分：有一定独特角度或新鲜表达
  7-8分：观点较为独特，提供新视角
  9-10分：极具独特性，颠覆性或创新性思考

  评分标准：
  - 是否提出反常识观点？
  - 是否有独特的类比或解释？
  - 是否发现了他人未注意的联系？
  - 是否挑战了主流看法？

  推文：{tweet_content}

  仅输出分数（0-10）。
  "

  批量处理：
  - 每次评估30条
  - 对于"生活日常"等非观点类内容，可给予默认分5分

  独特性调整因子
  对于某些类型内容，调整独特性权重：

  IF 推文类型 == "生活日常":
    # 日常分享不强求独特性
    uniqueness_weight = 0.5
    
  IF 推文类型 == "观点态度":
    # 观点类应强调独特性
    uniqueness_weight = 1.5

  IF 推文类型 == "知识分享":
    # 知识类更看重实用性而非独特性
    uniqueness_weight = 0.8

  adjusted_uniqueness = uniqueness_score × uniqueness_weight
  # 仍然clip到0-10

  3.2.4 可读性评分

  句长方差（Sentence Length Variance）
  FOR EACH 推文:
    sentences = 句子列表
    sentence_lengths = [len(s) for s in sentences]
    
    mean_length = np.mean(sentence_lengths)
    variance = np.var(sentence_lengths)

    # 方差越大，句式越不统一，可读性可能受影响
    # 但适度变化是好的

    IF variance < 10:
      # 句长过于统一，单调
      readability_from_variance = 6
    ELIF 10 ≤ variance < 50:
      # 适度变化，理想
      readability_from_variance = 10
    ELIF 50 ≤ variance < 100:
      # 变化较大，可接受
      readability_from_variance = 8
    ELSE:
      # 变化过大，可能难读
      readability_from_variance = 5

  文本复杂度（基于平均词长和句长）
  complexity = (avg_word_length × 0.5 + avg_sentence_length / 10 × 0.5)

  # 中文特点：
  # - 理想词长：1.5-2.0字
  # - 理想句长：15-25字

  IF avg_sentence_length < 10:
    sentence_score = 7  # 过短，信息不足
  ELIF 10 ≤ avg_sentence_length < 25:
    sentence_score = 10  # 理想
  ELIF 25 ≤ avg_sentence_length < 40:
    sentence_score = 8  # 偏长
  ELSE:
    sentence_score = 5  # 过长，难读

  IF avg_word_length < 1.3:
    word_score = 7  # 过于简单
  ELIF 1.3 ≤ avg_word_length < 2.2:
    word_score = 10  # 理想
  ELSE:
    word_score = 6  # 复杂词过多

  readability_from_complexity = (sentence_score + word_score) / 2

  可读性综合分
  readability_score = (
    readability_from_variance × 0.4 +
    readability_from_complexity × 0.6
  )

  # 范围：0-10分

  3.2.5 结构完整性评分

  结构元素检查
  FOR EACH 推文:

    has_opening = 判断有开头（问句/场景/引用/观点）
    has_body = 判断有主体（字数>30 且 句数>1）
    has_closing = 判断有结尾（总结/提问/号召/留白）
    
    completeness_score = (
      has_opening × 3 +   # 开头权重3
      has_body × 4 +      # 主体权重4（最重要）
      has_closing × 3     # 结尾权重3
    )

    # 映射到0-10分
    completeness_score = completeness_score × 10 / 10

  开头判定细则：
  - 以？开始 → 有开头
  - 以"今天/刚刚/最近/昨天"开始 → 有开头
  - 以引号开始 → 有开头
  - 以"我认为/我发现/我觉得"开始 → 有开头
  - 否则 → 无明确开头

  主体判定：
  - 字数 > 30 AND 句数 > 1 → 有主体

  结尾判定：
  - 最后一句是问句 → 有结尾
  - 包含"总之/所以/因此" → 有结尾
  - 包含"推荐/试试/建议" → 有结尾
  - 以……或emoji结尾 → 有结尾

  3.2.6 内容质量综合分（CQ）

  加权综合
  CQ = (
    info_density_score × 0.25 +        # 信息密度 25%
    emotion_score × 0.20 +              # 情感强度 20%
    adjusted_uniqueness × 0.30 +       # 观点独特性 30%
    readability_score × 0.15 +         # 可读性 15%
    completeness_score × 0.10          # 完整性 10%
  )

  # 范围：0-10分

  评级：
  IF CQ < 4: "待改进"
  IF 4 ≤ CQ < 6: "及格"
  IF 6 ≤ CQ < 8: "良好"
  IF CQ ≥ 8: "优秀"

  3.3 综合表现分

  3.3.1 Overall Score计算

  基础公式
  OS = α × NES_normalized + β × CQ

  其中：
  α = 0.6  # 互动表现权重
  β = 0.4  # 内容质量权重

  NES归一化：
  # NES的原始范围可能很大，需要归一化到0-10
  NES_normalized = min(NES / user_median_NES × 5, 10)
  # 以用户中位数为基准，中位数=5分

  完整计算：
  OS = 0.6 × NES_normalized + 0.4 × CQ

  # 范围：0-10分

  分级标准
  爆款级（Viral）：OS ≥ 8.0
  - 顶尖内容，互动和质量都很高
  - 值得深度分析和复用
  - 占比目标：<10%

  优秀级（Excellent）：7.0 ≤ OS < 8.0
  - 高质量内容，有借鉴价值
  - 可作为模板参考
  - 占比目标：15-25%

  良好级（Good）：6.0 ≤ OS < 7.0
  - 超过平均水平
  - 有可圈可点之处
  - 占比目标：20-30%

  普通级（Average）：4.0 ≤ OS < 6.0
  - 基准水平
  - 占比目标：30-40%

  待优化级（Needs Improvement）：OS < 4.0
  - 低于期望
  - 需分析原因
  - 占比目标：<15%

  3.3.2 评分可视化建议

  分数分布图
  生成直方图：
  X轴：OS分数区间 [0-1), [1-2), ..., [9-10]
  Y轴：推文数量

  标注：
  - 中位数线
  - 平均分线
  - 各等级分界线

  二维散点图
  X轴：NES（互动表现）
  Y轴：CQ（内容质量）

  四个象限：
  - 右上（高互动+高质量）：明星内容
  - 右下（高互动+低质量）：意外爆款（分析原因）
  - 左上（低互动+高质量）：遗珠（可能是时机/话题问题）
  - 左下（低互动+低质量）：需改进

  用颜色标注主题类别，发现哪类主题更容易落在哪个象限

  时间序列图
  X轴：时间（按月）
  Y轴：平均OS

  显示OS的变化趋势：
  - 是否在进步？
  - 哪个时期表现最好？
  - 最近趋势如何？